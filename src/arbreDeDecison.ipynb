import numpy as np
import sklearn
import matplotlib.pyplot as plt
import scipy.stats
import pandas as pd

df = pd.read_csv (r'/home/benammar/Bureau/workspacePython/F1.csv')
print(df.shape)

#Nous disposons de 279 observations et 105 variables
rom sklearn.model_selection import train_test_split
all_inputs = df[['AS','HS','AST','HST','HC','AC']].values
all_labels = (df['FTHG'] - df['FTAG']).values
(training_inputs,testing_inputs,training_classes,testing_classes) = train_test_split(all_inputs, all_labels, test_size=0.25, random_state=1)
from sklearn.tree import DecisionTreeClassifier

# Create the classifier
decision_tree_classifier = DecisionTreeClassifier()
# Train the classifier on the training set
decision_tree_classifier.fit(training_inputs, training_classes)
# Validate the classifier on the testing set using classification accuracy
decision_tree_classifier.score(testing_inputs, testing_classes)
#Nous avons 7 variables non numériques de type object
#subdiviser les données en échantillons d'apprentissage et de test
feature_cols = ['FTAG','AS','HS','AST','HST','HC','AC']
y= df['FTHG'] - df['FTAG'] #la différence des buts entre les deux équipes si c'est sup à 0 alors l'équipe a gagné
#df.insert(106,"nb_buts",y)
feature_target=df.nb_buts
#train, y_test = train_test_split(X,df.FTAG, test_size=0.3, random_state=1) # # 70% training and 30% test
dfTrain, dfTest = train_test_split(df,test_size=,random_state=1,stratify=df.nb_buts)
#accuracé de 22 pourcent, ce n'est pas bien
